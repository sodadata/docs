{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About Soda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soda is a Python library that facilitates data quality assessment, validation, and monitoring within your data pipelines and analytical workflows.\n",
    "\n",
    "### Key Features\n",
    "\n",
    "* Data validation: Soda provides 25+ built-in validation rules that help you ensure data conforms to expected formats, ranges, constraints, and integrity rules.\n",
    "* Data vrofiling: Soda helps you understand your data by generating descriptive statistics and summaries, such as data distributions, frequency distributions, and null value counts.\n",
    "* Data monitoring: With Soda, you can set up automated data quality monitoring tasks to regularly assess the health of your data.\n",
    "* Custom validation rules: Beyond the built-in validation rules, you can create custom rules tailored to your specific data requirements and business logic.\n",
    "* Integration with data pipelines: Soda integrates with your existing data pipelines so that you can easily check data quality at multiple points during data processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Soda\n",
    "\n",
    "Refer to Soda documentation: https://docs.soda.io/soda/quick-start-databricks.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install a Soda Library package with Apache Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8e1fb43-2e89-4e4f-a823-1398000b2668",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install -i https://pypi.cloud.soda.io soda-spark-df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Scan from Soda Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A scan is a command that executes checks to extract information about data in a dataset. Soda uses the input you provide to prepare SQL queries that it runs against the data in one or more datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soda.scan import Scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Spark DataFrame, or use the Spark API to read data and create a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Spark DataFrame is a distributed collection of data organized into named columns, providing a structured and tabular representation of data within the Apache Spark framework. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.table(\"delta.`/databricks-datasets/adventureworks/tables/adventureworks`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a view that SodaCL uses as a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"adventureworks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a scan object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan = Scan()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set a scan definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a scan definition to configure which data to scan and how to execute the scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.set_scan_definition_name(\"Databricks Notebook\")\n",
    "scan.set_data_source_name(\"spark_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach a Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.add_spark_session(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define checks for datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Soda Check is a test that Soda Library performs when it scans a dataset in your data source. You can define your checks in-line in the notebook, or define them in a separate checks.yml fail that is accessible by Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checks = \"\"\"\n",
    "checks for dim_customer:\n",
    "  - invalid_count(email_address) = 0:\n",
    "      valid format: email\n",
    "      name: Ensure values are formatted as email addresses\n",
    "  - missing_count(last_name) = 0:\n",
    "      name: Ensure there are no null values in the Last Name column\n",
    "  - duplicate_count(phone) = 0:\n",
    "      name: No duplicate phone numbers\n",
    "  - freshness(date_first_purchase) < 7d:\n",
    "      name: Data in this dataset is less than 7 days old\n",
    "  - schema:\n",
    "      warn:\n",
    "        when schema changes: any\n",
    "      name: Columns have not been added, removed, or changed\n",
    "sample datasets:\n",
    "  datasets:\n",
    "    - include dim_%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OR, define checks in a file accessible via Spark, then use the scan.add_sodacl_yaml method to retrieve the checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.add_sodacl_yaml_str(checks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Soda Cloud\n",
    "Add your Soda Cloud connection configuration using the API Keys you create in Soda Cloud. Sign up for a Soda Cloud account for a free, 45-day trial at https://cloud.soda.io/signup.\n",
    "Use cloud.soda.io for EU region\n",
    "Use cloud.us.soda.io for US region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config =\"\"\"\n",
    "soda_cloud:\n",
    "  host: cloud.soda.io\n",
    "  api_key_id: 399b**3c9\n",
    "  api_key_secret: hNSg7**1Q\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OR, configure the connection details in a file accessible via Spark, then use the scan.add_configuration_yaml method to retrieve the config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.add_configuration_yaml_str(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute a scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the Scan object for methods to inspect the scan result\n",
    "The following prints all logs to console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scan.get_logs_text()) "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Soda Library Demo",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
